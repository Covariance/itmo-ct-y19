{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811d1fcc-2a1a-449e-9834-b988ed4af55f",
   "metadata": {},
   "source": [
    "# Натянуть сову на линейное пространство\n",
    "\n",
    "Создайте эмбеддинги слов и визуализируйте векторные операции над ними: сложение, вычитание, взятие ближайшего, дальнейшего и прочее. Сравните качество представлений gensim и BERT с точки зрения операций над словами, докажите примерами.\n",
    "\n",
    "Для создания эмбеддингов с gensim обучите модель на нормализованных текстовых данных. Данные найдите на kaggle или выберите один из предложенных датасетов. Для создания эмбеддингов с BERT используйте предобученные модели.\n",
    "\n",
    "Предлагаемые датасеты:\n",
    " - [sentiment твитов про ковид](https://www.kaggle.com/datatattle/covid-19-nlp-text-classification)\n",
    " - [Amazon product reviews](https://www.kaggle.com/kashnitsky/hierarchical-text-classification)\n",
    " - [Отзывы интернет-магазина](https://www.kaggle.com/shymammoth/shopee-reviews)\n",
    " - [Тексты статей конференции NIPS](https://www.kaggle.com/rowhitswami/nips-papers-1987-2019-updated?select=papers.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31590c68-4b25-4aaf-8a80-5fc16c0f780d",
   "metadata": {},
   "source": [
    "# Projector\n",
    "\n",
    "Из прошлого задания вы выяснили наиболее хорошую для представления связей между словами модель. Спроецируйте ~2-3 тысячи наиболее популярных слов из выбранного корпуса в tensorflow projector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
