{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af588a75-b5f3-4381-a252-ac1ab7fae488",
   "metadata": {},
   "source": [
    "# Анализ изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db77370-d0ac-4312-be15-16e0414a2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b6034c-f40b-4c8b-9d59-74ace5a450c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb70b76-0870-408a-9a68-32f826bc97ab",
   "metadata": {},
   "source": [
    "Внаглую украдем трансформацию с лекции, кое-что добавив: так как resnet, которым мы воспользуемся дальше, кушает 3х-канальные изображения, то нам нужно превратить наш ЧБ-датасет в RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100cd9d3-8bb1-4c0e-bdb7-64acf463f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as ttrans\n",
    "\n",
    "train_transform = ttrans.Compose([\n",
    "    ttrans.Lambda(lambda image: image.convert('RGB')),\n",
    "    ttrans.Pad(4),\n",
    "    ttrans.RandomHorizontalFlip(),\n",
    "    ttrans.RandomCrop(32),\n",
    "    ttrans.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = ttrans.Compose([\n",
    "    ttrans.Lambda(lambda image: image.convert('RGB')),\n",
    "    ttrans.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da125c9-8d8e-43ec-8c0d-0f61b978e63e",
   "metadata": {},
   "source": [
    "Я пытался скачать CelebA, но он превысил дневной лимит скачиваний ну Google Drive, как говорится в [этом issue](https://github.com/rasbt/stat453-deep-learning-ss21/issues/4). Потом я попробовал с STL10, который по счастливому стечению обстоятельств похож на Cifar идейно, но он обещал скачиваться трое суток. В итоге мой выбор пал на Fashion MNIST, который выглядит дешево и сердито. Не хочется опять превращать ноутбук в кипятильник."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3282719b-7f4c-4d9d-9805-dfa29f0a9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7011af6c652344518f2c4e70e772ed25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/train/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b44b5b29e84f14845ebcd70a5da7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/train/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57588570ac5d483bb9517de3f79114cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/train/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a8a5cbcc234790bdbbba34d56e667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/train/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/train/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7144f16ef2142dab60794a76ca321b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/test/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d74d60bcb64864b34d6c18c983c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35826512b7fd4fc3a7fda2ecd6f519d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bb32a482fe49ed826ef28690540450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/test/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "train_dataset = FashionMNIST(\n",
    "    root='./FashionMNIST/train',\n",
    "    train=True, \n",
    "    transform=train_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = FashionMNIST(\n",
    "    root='./FashionMNIST/test',\n",
    "    train=False, \n",
    "    transform=test_transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabddcd-2dcf-46da-959f-67e0c3868df9",
   "metadata": {},
   "source": [
    "Ещё одна фича отправляется к нам прямиком из ноутбука с лекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eaacaf5-7423-45b3-80ca-fb59e4c301bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=128, \n",
    "        shuffle=True\n",
    "    ),\n",
    "    'val': DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=128, \n",
    "        shuffle=False\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ecce4c-b531-473a-b3ec-6bd88db89655",
   "metadata": {},
   "source": [
    "Сделаем класс для нашей модельки. Я решил не выпендриваться и взять `resnet50` в качестве основы модели, как и в лекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a488ad5c-c02f-425c-ac0a-b9f35eafdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self, ouput_dim, **kwargs):\n",
    "        super(FashionClassifier, self, **kwargs).__init__() \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1000, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, ouput_dim)\n",
    "        )\n",
    "    \n",
    "    def embed(self, x):\n",
    "        return self.fc1(self.model(x))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        resnet_out = self.embed(x)\n",
    "        return self.fc2(resnet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d54807-24d6-4576-a2e0-887110db5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# У нас десять классов одежды\n",
    "# CUDA у меня нету, но ВДРУГ КТО-ТО РЕШИТ ЗАПУСТИТЬ НА НЕЙ\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = FashionClassifier(10)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54022296-bfd5-4459-a73a-d842a43f73cb",
   "metadata": {},
   "source": [
    "Опять похитим сниппет с лекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af559f8c-221e-43c1-ab98-8ceeb0f0c88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39341c603875404782bce17c95445894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Whole pipeline:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1feb69a6670a42b38c4259412713a239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1. Phase: train:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8446 Acc: 0.3513 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d900b2d73b940379a0999aa7a2f01d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1. Phase: val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 19.4720 Acc: 0.1061 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce81b38cc0c40a898c48191ac97dc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2. Phase: train:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.5449 Acc: 0.4573 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc0feca2e5943c197ba422d966daacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2. Phase: val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 14.5194 Acc: 0.1246 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3a9dda54c541259d4eff5dea2f4885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3. Phase: train:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.4615 Acc: 0.4803 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a0cfc0b7a84c19b82245e85a84bd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3. Phase: val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 13.3688 Acc: 0.1109 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875cdba0041e482baef61af58df1ad65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4. Phase: train:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.4178 Acc: 0.4934 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14754b0d526b4a7baceeef6576abf48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4. Phase: val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 14.0200 Acc: 0.1163 "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "loss_hist = {'train': [], 'val': []}\n",
    "acc_hist = {'train': [], 'val': []}\n",
    "\n",
    "# Важно! В данном примере точность используется для упрощения.\n",
    "# Никогда не используйте её если у вас несбалансированная выборка\n",
    "# Возьмите лучше F_score или ROC_AUC (об этом вам потом расскажут)\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "# Основной алгоритм обучения\n",
    "for epoch in trange(epochs, desc='Whole pipeline'):\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        dataloader = dataloaders[phase]\n",
    "        \n",
    "        # Это условие необходимо так как у нас есть слой DropOut\n",
    "        # И на валидации его принято фиксировать\n",
    "        if phase == 'train':\n",
    "            model.train() \n",
    "        elif phase == 'val':\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        \n",
    "        # Проходимся по набору данных\n",
    "        for (X_batch, y_batch) in tqdm(dataloader, desc=f'Epoch: {epoch + 1}. Phase: {phase}'):\n",
    "            # Нормализуем наши данные\n",
    "            X_batch = X_batch / 255\n",
    "            X_batch = ttrans.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(X_batch)\n",
    "            \n",
    "            # Переносим на устройство\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Для корректного обучения перед каждым шагом необходимо сбрасывать прошлые ошибки\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                y_pred = model(X_batch)\n",
    "                \n",
    "                loss_value = loss_function(y_pred, y_batch)\n",
    "                y_pred_class = y_pred.argmax(dim=1)\n",
    "                \n",
    "                # На обучении мы хотим учиться в зависимости от ошибки\n",
    "                if phase == 'train':\n",
    "                    loss_value.backward()\n",
    "                    optimizer.step()\n",
    "                   \n",
    "            # Аггрегируем ошибку и точность\n",
    "            running_loss += loss_value.item()\n",
    "            running_acc += (y_pred_class == y_batch.data).float().mean().data.cpu().numpy()\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = running_acc / len(dataloader)\n",
    "        \n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} ', end='')\n",
    "        \n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "        acc_hist[phase].append(epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55eaee4-c4cf-429a-bddc-1b3831dd7988",
   "metadata": {},
   "source": [
    "Давайте теперь всё наше чудо отобразим в тензорборде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc141e9-a2ef-49d9-bccf-817a5c9a0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "with SummaryWriter() as writer:\n",
    "    for epoch in range(4):\n",
    "        writer.add_scalar('Loss/train', loss_hist['train'][epoch], epoch)\n",
    "        writer.add_scalar('Loss/val', loss_hist['val'][epoch], epoch)\n",
    "        writer.add_scalar('Accuracy/train', acc_hist['train'][epoch], epoch)\n",
    "        writer.add_scalar('Accuracy/val', acc_hist['val'][epoch], epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01531f1-2e1e-47b5-a28b-b3ba41fea977",
   "metadata": {},
   "source": [
    "А почему он их три штуки делает? Ну да ладно. Вообще это надо было делать по ходу дела, пока моделька училась. Давайте теперь нарисуем эмбеддинги. \n",
    "\n",
    "Перед этим надо сделать небольшой хак, потому что pytorch не очень справляется с эмбеддингами в этой версии: [тык на ишью](https://github.com/pytorch/pytorch/issues/30966)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928064ea-b22d-4e6b-807e-8f503c22f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hackity hack\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f1fc4b-ecba-49e4-b485-08b81880ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = [train_dataset[i] for i in range(1000)]\n",
    "xs, ys = zip(*train_items)\n",
    "\n",
    "xs = torch.stack(xs)\n",
    "features = xs.mean(dim=1).view(-1, 32 * 32)\n",
    "\n",
    "with SummaryWriter() as writer:\n",
    "    writer.add_embedding(features, metadata=ys, label_img=xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec82ac0-63b1-455e-a5d8-37cf9c9e3d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d78ee3-8cd0-4cd8-bc43-cb6ccb07eadf",
   "metadata": {},
   "source": [
    "That's all, folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
